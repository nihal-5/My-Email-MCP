#!/bin/bash

# ğŸš€ OLLAMA SETUP FOR M2 MACBOOK AIR
# Quick 5-minute installation

echo "ğŸ¤– Setting up LOCAL LLM on your M2 MacBook Air..."
echo ""

# Check if Homebrew is installed
if ! command -v brew &> /dev/null; then
    echo "âŒ Homebrew not found. Installing..."
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
fi

# Install Ollama
echo "ğŸ“¦ Installing Ollama..."
brew install ollama

# Start Ollama service in background
echo "ğŸš€ Starting Ollama service..."
ollama serve > /tmp/ollama.log 2>&1 &
sleep 3

# Download Llama 3.2 3B (for email classification)
echo ""
echo "ğŸ“¥ Downloading Llama 3.2 3B (2GB - perfect for M2!)..."
echo "This will take 2-3 minutes depending on your internet..."
ollama pull llama3.2:3b

# Optional: Download Llama 3.2 8B (for future resume generation)
echo ""
read -p "ğŸ“¥ Download Llama 3.2 8B (5GB) for Phase 2? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ“¥ Downloading Llama 3.2 8B..."
    ollama pull llama3.2:8b
fi

# Test the installation
echo ""
echo "ğŸ§ª Testing Llama 3.2 3B..."
echo ""
ollama run llama3.2:3b "Is this a job posting? Answer YES or NO. Text: We are hiring a DevOps Engineer with AWS experience."

echo ""
echo "âœ… SETUP COMPLETE!"
echo ""
echo "ğŸ“Š Your M2 MacBook Air is now running LOCAL AI!"
echo ""
echo "ğŸ’° Cost saved per month: $300+ (email classification)"
echo "âš¡ Speed: 1-2 seconds per classification"
echo "ğŸ¯ Quality: 80-85% (good enough!)"
echo ""
echo "ğŸš€ Ready to integrate with your job bot!"
echo ""
echo "ğŸ“ Next steps:"
echo "1. Check Ollama status: ollama list"
echo "2. Test a query: ollama run llama3.2:3b 'your question'"
echo "3. Run the job bot: npm start"
echo ""
